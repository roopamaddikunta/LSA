{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['sci.med']\n",
    "dataset = fetch_20newsgroups(subset='all',shuffle=True, random_state=42, categories=categories)\n",
    "corpus = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus= [x.lower() for x in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'from: dstock@hpqmoca.sqf.hp.com (david stockton)\\nsubject: re: krillean photography\\nnntp-posting-host: hpqmocb.sqf.hp.com\\norganization: hewlett-packard ltd, south queensferry, scotland\\nx-newsreader: tin [version 1.1 pl8.8]\\nlines: 23\\n\\nvinci (filipe@vxcrna.cern.ch) wrote:\\n\\n\\n\\n:  how about kirlian imaging ? i believe the faq for sci.skeptics (sp?)\\n:  has a nice write-up on this. they would certainly be most supportive\\n:  on helping you to build such a device and connect to a 120kvolt\\n:  supply so that you can take a serious look at your \"aura\"... :-)\\n\\n:  filipe santos\\n:  cern - european laboratory for particle physics\\n:  switzerland\\n\\n\\n    this has to be the only, generally accepted, method of using common \\nphysics lab equipment to find certain answers to all the questions about\\nafterlifes, heavens, hells, purgatory, gods etc. krillean photography\\nwill probably be ignored as insignificant compared to these larger\\neternal verities. publishing your results could be a bit of a problem,\\nthough.\\n\\n   cheers\\n             david\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Roopa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have run this several times to find the stopwords and to make sense of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopset=set(stopwords.words('english'))\n",
    "stopset.update(['\\n','\\t','pitt','geb','pitt edu','cs pitt','cs pitt edu','pit edu gordon','edu','gordon','gordon banks','com','lines','would','well','soon','writes','many','cs','see','reply','know','like',\n",
    "                'good','us','posting','one','new','article','reply','one','banks subject','reply geb','reply geb cs','know','way','00 00 31','00 00 gmt','00 09',\n",
    "                'geb cs','host','msg','banks','people','subject','get','00 00am','think','00 09','take','1993','newsletter',\n",
    "                  'quack','sol1','gps','also','take','organization','first','may','92','much','might','tell','etc','univ','school','time','long','pittsburg','two',\n",
    "                   'part','anything','12 92','since','use','carl','12','enogh','said',\n",
    "                  'also','info','without','seems','says','even','ca','say','92','could',\n",
    "                     '10','university','aisun3','aisun3 ai','mcovingt','covington',\n",
    "                      'org','object','krillean','bill','photograpy','krillean photography',\n",
    "                      'kirlian','jon noring','noring','jon','noring netcom','really','book',\n",
    "                     'yeah','course','00 00 gmt','david','00 09','still','dr','called',\n",
    "                       'anyone','go','mail','years','really','mail','seen','dyer',\n",
    "                      'back','gif','keyboard','however','00 09 31',\n",
    "'00 00 interested','00 00am'\n",
    "'00 00am continental','enough'\n",
    ",'david','00 00 gmt','something','00 00am','right','sci','00 00','believe','read',\n",
    "'thanks','made','fact','david','harvard'\n",
    "            \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=True, ngram_range=(1,3))\n",
    "X=vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x236429 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 239 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 166957)\t0.0699132486111\n",
      "  (0, 33932)\t0.0699132486111\n",
      "  (0, 181701)\t0.0699132486111\n",
      "  (0, 170822)\t0.0699132486111\n",
      "  (0, 226082)\t0.0699132486111\n",
      "  (0, 79094)\t0.0699132486111\n",
      "  (0, 120730)\t0.0699132486111\n",
      "  (0, 51653)\t0.0699132486111\n",
      "  (0, 112023)\t0.0699132486111\n",
      "  (0, 106434)\t0.0699132486111\n",
      "  (0, 166490)\t0.0699132486111\n",
      "  (0, 159211)\t0.0699132486111\n",
      "  (0, 94420)\t0.0699132486111\n",
      "  (0, 171082)\t0.0699132486111\n",
      "  (0, 100565)\t0.0699132486111\n",
      "  (0, 100325)\t0.0699132486111\n",
      "  (0, 17654)\t0.0699132486111\n",
      "  (0, 172171)\t0.0699132486111\n",
      "  (0, 22866)\t0.0699132486111\n",
      "  (0, 44160)\t0.0699132486111\n",
      "  (0, 86259)\t0.0699132486111\n",
      "  (0, 78228)\t0.0699132486111\n",
      "  (0, 119892)\t0.0699132486111\n",
      "  (0, 159708)\t0.0699132486111\n",
      "  (0, 51170)\t0.0699132486111\n",
      "  :\t:\n",
      "  (0, 234567)\t0.0354168764702\n",
      "  (0, 44565)\t0.0510327228528\n",
      "  (0, 44130)\t0.115516203649\n",
      "  (0, 228084)\t0.0610227811999\n",
      "  (0, 86028)\t0.126375739279\n",
      "  (0, 226711)\t0.0631878696396\n",
      "  (0, 6411)\t0.0413443262398\n",
      "  (0, 160428)\t0.0466472599498\n",
      "  (0, 226103)\t0.0394905801557\n",
      "  (0, 214338)\t0.0403732493799\n",
      "  (0, 144307)\t0.0381161918072\n",
      "  (0, 187964)\t0.0699132486111\n",
      "  (0, 171879)\t0.0699132486111\n",
      "  (0, 197276)\t0.0491488909433\n",
      "  (0, 127472)\t0.0577581018243\n",
      "  (0, 153091)\t0.0631878696396\n",
      "  (0, 101579)\t0.0631878696396\n",
      "  (0, 104502)\t0.0699132486111\n",
      "  (0, 145125)\t0.0191575233106\n",
      "  (0, 159093)\t0.076602020348\n",
      "  (0, 201198)\t0.0699132486111\n",
      "  (0, 104406)\t0.0924319182542\n",
      "  (0, 198953)\t0.139826497222\n",
      "  (0, 104499)\t0.0699132486111\n",
      "  (0, 72192)\t0.0699132486111\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 236429)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=27, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa=TruncatedSVD(n_components=27, n_iter=100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01393827,  0.00357797,  0.00252742, ...,  0.00022755,\n",
       "        0.00022755,  0.00022755])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "candida\n",
      "yeast\n",
      "medical\n",
      "science\n",
      "food\n",
      "patients\n",
      "disease\n",
      "doctor\n",
      "rind\n",
      "diet\n",
      " \n",
      "Concept 1:\n",
      "ai\n",
      "uga\n",
      "ai uga\n",
      "georgia\n",
      "athens\n",
      "programs\n",
      "michael\n",
      "corn\n",
      "706\n",
      "706 542\n",
      " \n",
      "Concept 2:\n",
      "photography\n",
      "caltech\n",
      "pictures\n",
      "hold responsible\n",
      "related vax\n",
      "related vax vms\n",
      "mitre\n",
      "unlv\n",
      "spelling\n",
      "lydick\n",
      " \n",
      "Concept 3:\n",
      "yeast\n",
      "netcom\n",
      "candida\n",
      "body\n",
      "nystatin\n",
      "00 00am continental\n",
      "chastity\n",
      "chastity intellect\n",
      "intellect\n",
      "n3jxp\n",
      " \n",
      "Concept 4:\n",
      "hiv\n",
      "health\n",
      "fat\n",
      "medical\n",
      "netcom\n",
      "number\n",
      "allergic\n",
      "aids\n",
      "nystatin\n",
      "syndrome\n",
      " \n",
      "Concept 5:\n",
      "candida\n",
      "medical\n",
      "yeast\n",
      "vaginal\n",
      "fungal\n",
      "bacteria\n",
      "yogurt\n",
      "antibiotic\n",
      "therapy\n",
      "vms\n",
      " \n",
      "Concept 6:\n",
      "hiv\n",
      "cancer\n",
      "treatment\n",
      "candida\n",
      "aids\n",
      "research\n",
      "april\n",
      "hicnet\n",
      "hicnet medical\n",
      "hicnet medical page\n",
      " \n",
      "Concept 7:\n",
      "disease\n",
      "doctor\n",
      "cause\n",
      "fat\n",
      "research\n",
      "problems\n",
      "netcom\n",
      "lyme\n",
      "weeks\n",
      "seem\n",
      " \n",
      "Concept 8:\n",
      "need\n",
      "candida\n",
      "diabetes\n",
      "mil\n",
      "studies\n",
      "find\n",
      "cadre\n",
      "cadre dsl\n",
      "cadre dsl shameful\n",
      "chastity intellect cadre\n",
      " \n",
      "Concept 9:\n",
      "candida\n",
      "nntp\n",
      "disease\n",
      "health\n",
      "problem\n",
      "doctor\n",
      "steve\n",
      "olney\n",
      "15\n",
      "yeast\n",
      " \n",
      "Concept 10:\n",
      "doctor\n",
      "vitamin\n",
      "symptoms\n",
      "want\n",
      "medical\n",
      "try\n",
      "nystatin\n",
      "computer\n",
      "fat\n",
      "medicine\n",
      " \n",
      "Concept 11:\n",
      "00 09\n",
      "vitamin\n",
      "candida\n",
      "high\n",
      "post\n",
      "system\n",
      "bloom\n",
      "retinol\n",
      "general\n",
      "mucus membrane\n",
      " \n",
      "Concept 12:\n",
      "computer\n",
      "health\n",
      "need\n",
      "every\n",
      "study\n",
      "distribution world\n",
      "tobacco\n",
      "sensitivity\n",
      "cesarean\n",
      "hiv\n",
      " \n",
      "Concept 13:\n",
      "medical\n",
      "lyme\n",
      "health\n",
      "00 00am continental\n",
      "effects\n",
      "distribution\n",
      "less\n",
      "stones\n",
      "vms\n",
      "calcium\n",
      " \n",
      "Concept 14:\n",
      "patients\n",
      "yeast\n",
      "health\n",
      "candida\n",
      "sas\n",
      "system\n",
      "17\n",
      "person\n",
      "hiv\n",
      "taking\n",
      " \n",
      "Concept 15:\n",
      "help\n",
      "pain\n",
      "question\n",
      "jim\n",
      "doctors\n",
      "vitamin\n",
      "evidence\n",
      "lyme disease\n",
      "kidney\n",
      "science\n",
      " \n",
      "Concept 16:\n",
      "medical\n",
      "hiv\n",
      "problem\n",
      "sure\n",
      "aids\n",
      "00 00 gmt\n",
      "00 09\n",
      "gi\n",
      "symptoms\n",
      "mucus\n",
      " \n",
      "Concept 17:\n",
      "medicine\n",
      "computer\n",
      "make\n",
      "study\n",
      "high\n",
      "00 09 31\n",
      "studies\n",
      "heard\n",
      "gonorrhea\n",
      "chronic\n",
      " \n",
      "Concept 18:\n",
      "research\n",
      "computer\n",
      "tobacco\n",
      "lyme\n",
      "00 09 31\n",
      "smokeless\n",
      "smokeless tobacco\n",
      "doctor\n",
      "science\n",
      "taking\n",
      " \n",
      "Concept 19:\n",
      "00 09 31\n",
      "day\n",
      "cancer\n",
      "treatment\n",
      "distribution\n",
      "symptoms\n",
      "00 00\n",
      "computer\n",
      "things\n",
      "doctor\n",
      " \n",
      "Concept 20:\n",
      "science\n",
      "diet\n",
      "pittsburgh\n",
      "tobacco\n",
      "smokeless\n",
      "net\n",
      "smokeless tobacco\n",
      "netcom\n",
      "problem\n",
      "things\n",
      " \n",
      "Concept 21:\n",
      "00 00am continental\n",
      "sure\n",
      "lyme\n",
      "disease\n",
      "whether\n",
      "hiv\n",
      "pittsburgh\n",
      "lyme disease\n",
      "netcom\n",
      "cause\n",
      " \n",
      "Concept 22:\n",
      "candida\n",
      "health\n",
      "others\n",
      "science\n",
      "common\n",
      "drug\n",
      "going\n",
      "ago\n",
      "infection\n",
      "cause\n",
      " \n",
      "Concept 23:\n",
      "disease\n",
      "treatment\n",
      "pittsburgh\n",
      "medicine\n",
      "studies\n",
      "netcom\n",
      "typing\n",
      "rsi\n",
      "berkeley\n",
      "quite\n",
      " \n",
      "Concept 24:\n",
      "science\n",
      "00 00 gmt\n",
      "vms\n",
      "food\n",
      "depression\n",
      "nutrition\n",
      "pain\n",
      "anti\n",
      "ago\n",
      "lyme\n",
      " \n",
      "Concept 25:\n",
      "patients\n",
      "food\n",
      "00 09 31\n",
      "cancer\n",
      "probably\n",
      "evidence\n",
      "candida\n",
      "work\n",
      "scientific\n",
      "computer\n",
      " \n",
      "Concept 26:\n",
      "work\n",
      "someone\n",
      "computer science\n",
      "diet\n",
      "thing\n",
      "body\n",
      "maybe\n",
      "information\n",
      "00 09 31\n",
      "different\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    termsInComp = zip (terms, comp)\n",
    "    sortedTerms = sorted(termsInComp, key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"Concept %d:\" %i)\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candida is an infection, I think by yeast. It has somethig to do with how doctors treat patients who has it. And how it colonizes. \n",
    "And also there's cancer,hiv and other diseases that has been explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
